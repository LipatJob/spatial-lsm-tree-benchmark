{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59fb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = \"data/csv/osm21_sports.csv\"\n",
    "insert_batch_size = 50_000\n",
    "query_count = 200\n",
    "\n",
    "dataverse = \"LocationDb\"\n",
    "table_name = \"Locations_RTree_Constant\"\n",
    "\n",
    "dbHost = \"http://localhost:19002\"\n",
    "benchmark_plan_path = f\"commands/benchmark_plan_{dataverse}_{table_name}_{insert_batch_size}_{query_count}.sql\"\n",
    "\n",
    "# None means no limit\n",
    "debug_max_batches = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f95d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "with open(input_dataset, \"r\") as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        row = line.strip().split(\",\")\n",
    "        id = row[0]\n",
    "        locationX = row[1]\n",
    "        locationY = row[2]\n",
    "        description = row[3]\n",
    "        data.append([id, locationX, locationY, description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e6fa681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "import math\n",
    "import os\n",
    "\n",
    "def point(x, y):\n",
    "    return f'point(\"{x},{y}\")'\n",
    "\n",
    "def rectangle(x1, y1, x2, y2):\n",
    "    return f'rectangle(\"{x1},{y1} {x2},{y2}\")'\n",
    "\n",
    "def generate_insert_command(batch):\n",
    "    query_lines = []\n",
    "    query_lines.append(f\"INSERT INTO {table_name} ([\")\n",
    "    for row in batch:\n",
    "        id = row[0]\n",
    "        location_x = row[1]\n",
    "        location_y = row[2]\n",
    "        description = row[3]\n",
    "        is_last = (row == batch[-1])\n",
    "        query_lines.append(f'{{\"id\": {id}, \"location\": {point(location_x, location_y)}, \"description\": \"{description}\"}}{ \"\" if is_last else \",\" }')\n",
    "    query_lines.append(\"])\")\n",
    "    \n",
    "    return \"\".join(query_lines)\n",
    "\n",
    "def generate_query_commands(inserted_points):\n",
    "    queries = []\n",
    "    selected_points = random.sample(inserted_points, query_count)\n",
    "    for selected_point in selected_points:\n",
    "        location_x = selected_point[0]\n",
    "        location_y = selected_point[1]\n",
    "        stdev_x = 60\n",
    "        stdev_y = 20\n",
    "        stdev_scale = .2\n",
    "        offset_x = random.random() * stdev_x * stdev_scale\n",
    "        offset_y = random.random() * stdev_y * stdev_scale\n",
    "        start_x = float(location_x) - offset_x\n",
    "        start_y = float(location_y) - offset_y\n",
    "        end_x = float(location_x) + offset_x\n",
    "        end_y = float(location_y) + offset_y\n",
    "        \n",
    "        query = f\"SELECT COUNT(*) FROM {table_name} WHERE spatial_intersect(location, {rectangle(start_x, start_y, end_x, end_y)});\";\n",
    "        queries.append(query)\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd4f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "inserted_points = []\n",
    "current_batch = 0\n",
    "commands = []\n",
    "while True:\n",
    "    if debug_max_batches is not None and current_batch >= debug_max_batches:\n",
    "        break\n",
    "    batch_to_insert = data[current_batch * insert_batch_size:(current_batch + 1) * insert_batch_size]\n",
    "    if not batch_to_insert: # no more data to insert\n",
    "        break\n",
    "    \n",
    "    insert_command = generate_insert_command(batch_to_insert)\n",
    "    inserted_points.extend(map(lambda x: (x[1], x[2]), batch_to_insert))\n",
    "    \n",
    "    query_commands = generate_query_commands(inserted_points)\n",
    "    commands.append(insert_command)\n",
    "    commands.extend(query_commands)\n",
    "    \n",
    "    current_batch += 1\n",
    "   \n",
    "# write the commands to a file\n",
    "benchmark_dir = os.path.dirname(benchmark_plan_path)\n",
    "if not os.path.exists(benchmark_dir):\n",
    "    os.makedirs(benchmark_dir)\n",
    "with open(benchmark_plan_path, \"w\") as f:\n",
    "    for command in commands:\n",
    "        f.write(command + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75985321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "logs_dir = \"./logs\"\n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d897f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_database_script = \"\"\"\n",
    "DROP DATAVERSE LocationDb IF EXISTS;\n",
    "CREATE DATAVERSE LocationDb;\n",
    "USE LocationDb;\n",
    "\n",
    "CREATE TYPE LocationType AS {\n",
    "    id: bigint,\n",
    "    location: point,\n",
    "    description: string\n",
    "};\n",
    "\n",
    "CREATE DATASET Locations_RTree_Constant(LocationType) PRIMARY KEY id;\n",
    "CREATE INDEX Location_RTree_Constant_Index on Locations_RTree_Constant(location) TYPE rtree ENFORCED;\n",
    "\n",
    "CREATE DATASET Locations_RTree_Concurrent(LocationType) PRIMARY KEY id;\n",
    "CREATE INDEX Locations_RTree_Concurrent_Index on Locations_RTree_Concurrent(location) TYPE rtree ENFORCED;\n",
    "\n",
    "CREATE DATASET Locations_BTree_Constant(LocationType) PRIMARY KEY id;\n",
    "CREATE INDEX Locations_BTree_Constant_Index on Locations_BTree_Constant(location) TYPE rtree ENFORCED;\n",
    "\n",
    "CREATE DATASET Locations_BTree_Concurrent(LocationType) PRIMARY KEY id;\n",
    "CREATE INDEX Locations_BTree_Concurrent_Index on Locations_BTree_Concurrent(location) TYPE rtree ENFORCED;\n",
    "\"\"\"\n",
    "response = requests.post(f\"{dbHost}/query/service\", data={'statement': create_database_script})\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59e65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to file\n",
      "To see the logs in real time: tail -f ./logs/benchmark_LocationDb_Locations_RTree_Constant_50000_200_1745757031.892.log\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "def execute_command(command, client_context_id=None):\n",
    "    return requests.post(f\"{dbHost}/query/service\", data={\n",
    "        'statement': command,\n",
    "        'dataverse': dataverse,\n",
    "        'client_context_id': client_context_id,\n",
    "    })\n",
    "\n",
    "log_file_path = f\"./logs/benchmark_{dataverse}_{table_name}_{insert_batch_size}_{query_count}_{str(time.time())}.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename = log_file_path,\n",
    "    filemode = 'a'\n",
    ")\n",
    "print(f\"Logging to file\")\n",
    "print(f\"To see the logs in real time: tail -f {log_file_path}\")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "with open(log_file_path, \"a\") as log:\n",
    "    with open(benchmark_plan_path, \"r\") as f:\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            index += 1\n",
    "            command = line.strip()\n",
    "            if not command:\n",
    "                continue\n",
    "            \n",
    "            command_type = \"insert\" if command.startswith(\"INSERT\") else \"query\"\n",
    "            event = f\"command.{command_type}\"\n",
    "            trace_id = str(index).zfill(10)\n",
    "            log.write(json.dumps({\"trace-id\": trace_id,\"event\": event,}) + \"\\n\")\n",
    "            response = execute_command(command, client_context_id=trace_id)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error: {response.json()}\")\n",
    "                log.write(json.dumps({\n",
    "                    \"trace_id\": json_response.get(\"clientContextID\"),\n",
    "                    \"event\": event,\n",
    "                    \"http.status\": response.status_code,\n",
    "                    \"status\": json_response.get(\"status\"),\n",
    "                    \"metrics\": json_response.get(\"metrics\"),\n",
    "                    \"error\": json_response.get(\"errors\"),\n",
    "                }) + \"\\n\")\n",
    "            else:\n",
    "                json_response = response.json()\n",
    "                log.write(json.dumps({\n",
    "                    \"trace_id\": json_response.get(\"clientContextID\"),\n",
    "                    \"event\": event,\n",
    "                    \"http.status\": response.status_code,\n",
    "                    \"status\": json_response.get(\"status\"),\n",
    "                    \"result_count\": len(json_response.get(\"results\", [])) if json_response.get(\"results\") else None,\n",
    "                    \"metrics\": json_response.get(\"metrics\"),\n",
    "                }) + \"\\n\")\n",
    "                        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
