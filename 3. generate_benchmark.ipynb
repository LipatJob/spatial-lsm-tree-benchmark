{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59fb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_batch_size = 1000\n",
    "query_count = 20\n",
    "\n",
    "\n",
    "dataverse = \"LocationDb\"\n",
    "table_name = \"Locations_RTree_Constant\"\n",
    "\n",
    "dbHost = \"http://localhost:19002\"\n",
    "benchmark_plan_path = f\"commands/benchmark_plan_{dataverse}_{table_name}_{insert_batch_size}_{query_count}.sql\"\n",
    "\n",
    "# None means no limit\n",
    "debug_max_batches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f95d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "with open(\"data/point_data_centroid.csv\", \"r\") as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        row = line.strip().split(\",\")\n",
    "        id = row[0]\n",
    "        locationX = row[1]\n",
    "        locationY = row[2]\n",
    "        description = row[3]\n",
    "        data.append([id, locationX, locationY, description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e6fa681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "import math\n",
    "\n",
    "def point(x, y):\n",
    "    return f'point(\"{x},{y}\")'\n",
    "\n",
    "def rectangle(x1, y1, x2, y2):\n",
    "    return f'rectangle(\"{x1},{y1} {x2},{y2}\")'\n",
    "\n",
    "def generate_insert_command(batch):\n",
    "    query_lines = []\n",
    "    query_lines.append(f\"INSERT INTO {table_name} ([\")\n",
    "    for row in batch:\n",
    "        id = row[0]\n",
    "        location_x = row[1]\n",
    "        location_y = row[2]\n",
    "        description = row[3]\n",
    "        is_last = (row == batch[-1])\n",
    "        query_lines.append(f'{{\"id\": {id}, \"location\": {point(location_x, location_y)}, \"description\": \"{description}\"}}{ \"\" if is_last else \",\" }')\n",
    "    query_lines.append(\"])\")\n",
    "    \n",
    "    return \"\".join(query_lines)\n",
    "\n",
    "def generate_query_commands(inserted_points):\n",
    "    queries = []\n",
    "    selected_points = random.sample(inserted_points, query_count)\n",
    "    for selected_point in selected_points:\n",
    "        location_x = selected_point[0]\n",
    "        location_y = selected_point[1]\n",
    "        stdev_x = 60\n",
    "        stdev_y = 20\n",
    "        stdev_scale = .3\n",
    "        offset_x = random.random() * stdev_x * stdev_scale\n",
    "        offset_y = random.random() * stdev_y * stdev_scale\n",
    "        start_x = float(location_x) - offset_x\n",
    "        start_y = float(location_y) - offset_y\n",
    "        end_x = float(location_x) + offset_x\n",
    "        end_y = float(location_y) + offset_y\n",
    "        \n",
    "        query = f\"SELECT location, description FROM {table_name} WHERE spatial_intersect(location, {rectangle(start_x, start_y, end_x, end_y)});\";\n",
    "        queries.append(query)\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd4f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "inserted_points = []\n",
    "current_batch = 0\n",
    "commands = []\n",
    "while True:\n",
    "    if debug_max_batches is not None and current_batch >= debug_max_batches:\n",
    "        break\n",
    "    batch_to_insert = data[current_batch * insert_batch_size:(current_batch + 1) * insert_batch_size]\n",
    "    if not batch_to_insert: # no more data to insert\n",
    "        break\n",
    "    \n",
    "    insert_command = generate_insert_command(batch_to_insert)\n",
    "    inserted_points.extend(map(lambda x: (x[1], x[2]), batch_to_insert))\n",
    "    \n",
    "    query_commands = generate_query_commands(inserted_points)\n",
    "    commands.append(insert_command)\n",
    "    commands.extend(query_commands)\n",
    "    \n",
    "    current_batch += 1\n",
    "   \n",
    "import os \n",
    "# write the commands to a file\n",
    "benchmark_dir = os.path.dirname(benchmark_plan_path)\n",
    "if not os.path.exists(benchmark_dir):\n",
    "    os.makedirs(benchmark_dir)\n",
    "with open(benchmark_plan_path, \"w\") as f:\n",
    "    for command in commands:\n",
    "        f.write(command + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75985321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "logs_dir = \"./logs\"\n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a59e65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to file\n",
      "To see the logs in real time: tail -f ./logs/benchmark_LocationDb_Locations_RTree_Constant_1000_20_1745686958.513091.log\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def execute_command(command):\n",
    "    return requests.post(f\"{dbHost}/query/service\", data={\n",
    "        'statement': command,\n",
    "        'dataverse': dataverse,\n",
    "    })\n",
    "\n",
    "log_file_path = f\"./logs/benchmark_{dataverse}_{table_name}_{insert_batch_size}_{query_count}_{str(time.time())}.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename = log_file_path,\n",
    "    filemode = 'a'\n",
    ")\n",
    "print(f\"Logging to file\")\n",
    "print(f\"To see the logs in real time: tail -f {log_file_path}\")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "with open(log_file_path, \"a\") as log:\n",
    "    with open(benchmark_plan_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            command = line.strip()\n",
    "            if command:\n",
    "                log.write(f\"Executing command\\n\")\n",
    "                response = execute_command(command)\n",
    "                if response.status_code != 200:\n",
    "                    log.write(f\"Error executing command: {response.status_code}\\n\")\n",
    "                else:\n",
    "                    json_response = response.json()\n",
    "                    result_count = len(json_response.get(\"results\", [])) if json_response.get(\"results\") else None\n",
    "                    request_id = json_response.get(\"requestID\")\n",
    "                    status = json_response.get(\"status\")\n",
    "                    metrics = json_response.get(\"metrics\")\n",
    "                    log.write(f\"Command executed successfully. Request ID: {request_id}, Status: {status}, Result Count: {result_count}, Metrics: {metrics}\\n\")\n",
    "                        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
